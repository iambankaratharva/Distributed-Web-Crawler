# Distributed-Web-Crawler
Distributed web crawler using analytics engine and a key-value store to handle large-scale web scraping. Implements polite crawling by adhering to robots.txt and limiting request rates. Store crawled pages in a KVS table, manage a URL queue, and handle redirects. Extract and normalize links for efficient and ethical web crawling.
